{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13084ad4-8e82-47da-9ea6-0a71ad0e910a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Single table column transformation (col names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c151b99b-aab5-4988-8537-7bc7952f8e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('mnt/silver/SalesLT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c2bbd3-23a4-45a3-8ec5-f4d6ab59a26b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('mnt/gold/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47b64bab-e7e6-472b-9e69-52fcf0cdd9d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('delta').load('/mnt/silver/SalesLT/Address/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee9f36da-3792-442b-89ff-e44623f6e510",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae7750c-fc0a-44d3-86b1-32a2c64336a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def rename_columns_to_snake_case(df):\n",
    "    \"\"\"\n",
    "    Convert column names from PascalCase or camelCase to snake_case in a PySpark DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame with columns to be renamed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with column names converted to snake_case.\n",
    "    \"\"\"\n",
    "    # Get the list of column names\n",
    "    column_names = df.columns\n",
    "\n",
    "    # Dictionary to hold old and new column name mappings\n",
    "    rename_map = {}\n",
    "\n",
    "    for old_col_name in column_names:\n",
    "        # Convert column name from PascalCase or camelCase to snake_case\n",
    "        new_col_name = \"\".join([\n",
    "            \"_\" + char.lower() if (\n",
    "                char.isupper()              # Check if the current character is uppercase\n",
    "                and idx > 0                 # Ensure it's not the first character\n",
    "                and not old_col_name[idx - 1].isupper()  # Ensure the previous character is not uppercase\n",
    "            ) else char.lower()  # Convert character to lowercase\n",
    "            for idx, char in enumerate(old_col_name)\n",
    "        ]).lstrip(\"_\")  # Remove any leading underscore\n",
    "\n",
    "        # Avoid renaming to an existing column name\n",
    "        if new_col_name in rename_map.values():\n",
    "            raise ValueError(f\"Duplicate column name found after renaming: '{new_col_name}'\")\n",
    "\n",
    "        # Map the old column name to the new column name\n",
    "        rename_map[old_col_name] = new_col_name\n",
    "\n",
    "    # Rename columns using the mapping\n",
    "    for old_col_name, new_col_name in rename_map.items():\n",
    "        df = df.withColumnRenamed(old_col_name, new_col_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# df = rename_columns_to_snake_case(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4f2ab4-9f3e-4d87-b713-9b0151be1a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = rename_columns_to_snake_case(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183f1d84-967a-414c-9e10-9bcf5880a6ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05f4ba7a-1c9a-4398-8b8b-189ffa058e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# All table columns transformation (col names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d877350-e6b1-4d13-9875-ac4c83bdcd3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To show the basic format of ls\n",
    "table_name = []\n",
    "\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT'):\n",
    "    table_name.append(i)\n",
    "\n",
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d6060f1-2bc6-45fb-8cb3-848c4d7725f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = []\n",
    "\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT'):\n",
    "    table_name.append(i.name.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b8d1a8-e67a-4c6a-b453-5f058e3283f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "697c0656-c84f-4eb6-ba9a-8760b2770a76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name in table_name:\n",
    "    path = '/mnt/silver/SalesLT/' + name\n",
    "    print(path)\n",
    "    df = spark.read.format('delta').load(path)\n",
    "\n",
    "    df = rename_columns_to_snake_case(df)\n",
    "\n",
    "    output_path = '/mnt/gold/SalesLT/' + name + '/'\n",
    "    df.write.format('delta').mode('overwrite').save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea99757c-a3c7-4067-827b-441119e09040",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c993fe-e26b-46ed-8503-6cb14a83dfa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If you get Schema error, run this\n",
    "# Check schema of Silver data\n",
    "silver_df = spark.read.format(\"delta\").load(\"/mnt/silver/SalesLT/Address/\")\n",
    "silver_schema = silver_df.printSchema()\n",
    "\n",
    "# Check schema of Gold data\n",
    "gold_df = spark.read.format(\"delta\").load(\"/mnt/gold/SalesLT/Address\")\n",
    "gold_schema = gold_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver2gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}